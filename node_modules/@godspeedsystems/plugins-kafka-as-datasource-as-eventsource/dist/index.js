"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.DEFAULT_CONFIG = exports.CONFIG_FILE_NAME = exports.Type = exports.SourceType = exports.EventSource = exports.DataSource = void 0;
const core_1 = require("@godspeedsystems/core");
const kafkajs_1 = require("kafkajs");
const fs_1 = __importDefault(require("fs"));
class DataSource extends core_1.GSDataSource {
    initClient() {
        return __awaiter(this, void 0, void 0, function* () {
            const kafka = new kafkajs_1.Kafka({
                clientId: this.config.clientId,
                brokers: this.config.brokers,
                ssl: {
                    rejectUnauthorized: this.config.ssl.reject,
                    key: fs_1.default.readFileSync(this.config.ssl.key, 'utf-8'),
                    cert: fs_1.default.readFileSync(this.config.ssl.cert, 'utf-8'),
                    ca: [fs_1.default.readFileSync(this.config.ssl.ca, 'utf-8')],
                },
                logLevel: kafkajs_1.logLevel.INFO, // optional, for logging
            });
            return kafka;
        });
    }
    execute(ctx, args) {
        return __awaiter(this, void 0, void 0, function* () {
            try {
                const { topic, message, meta: { fnNameInWorkflow }, } = args;
                let method = fnNameInWorkflow.split(".")[2];
                if (this.client) {
                    if (method === "producer") {
                        const producer = this.client.producer();
                        yield producer.connect();
                        let result = yield producer.send({
                            topic: topic,
                            messages: [{ value: JSON.stringify(message) }],
                        });
                        yield producer.disconnect();
                        return result;
                    }
                    else {
                        return "Invalid method";
                    }
                }
            }
            catch (error) {
                throw error;
            }
        });
    }
}
exports.DataSource = DataSource;
class EventSource extends core_1.GSDataSourceAsEventSource {
    subscribeToEvent(eventKey, eventConfig, processEvent) {
        return __awaiter(this, void 0, void 0, function* () {
            const client = this.client;
            const ds = eventKey.split(".")[0];
            const groupId = eventKey.split(".")[2];
            const _topic = eventKey.split('.')[1];
            if (client) {
                const consumer = client.consumer({ groupId: groupId });
                yield consumer.subscribe({
                    topic: _topic,
                    fromBeginning: true,
                });
                yield consumer.run({
                    eachMessage: (messagePayload) => __awaiter(this, void 0, void 0, function* () {
                        var _a;
                        const { message } = messagePayload;
                        let msgValue;
                        let status;
                        let data;
                        try {
                            msgValue = (_a = message === null || message === void 0 ? void 0 : message.value) === null || _a === void 0 ? void 0 : _a.toString();
                            data = {
                                body: JSON.parse(msgValue || ''),
                            };
                            status = 200;
                        }
                        catch (ex) {
                            status = 500;
                            return new core_1.GSStatus(false, 500, `Error in parsing kafka event data ${msgValue}`, ex);
                        }
                        const event = new core_1.GSCloudEvent("id", `${ds}.${_topic}.${groupId}`, new Date(message.timestamp), "kafka", "1.0", data, "messagebus", new core_1.GSActor("user"), "");
                        const res = yield processEvent(event, eventConfig);
                        if (!res) {
                            status = 500;
                        }
                        else {
                            status = 200;
                        }
                        return res;
                    }),
                });
            }
        });
    }
}
exports.EventSource = EventSource;
const SourceType = 'BOTH';
exports.SourceType = SourceType;
const Type = "kafka"; // this is the loader file of the plugin, So the final loader file will be `types/${Type.js}`
exports.Type = Type;
const CONFIG_FILE_NAME = "kafka"; // in case of event source, this also works as event identifier, and in case of datasource works as datasource name
exports.CONFIG_FILE_NAME = CONFIG_FILE_NAME;
const DEFAULT_CONFIG = {
    type: "kafka",
    clientId: "kafka_proj",
    brokers: ["kafka:9092"],
    log: { attributes: { eventsource_type: "kafka" } }
};
exports.DEFAULT_CONFIG = DEFAULT_CONFIG;
//# sourceMappingURL=index.js.map